{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1629726405580,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "jutVHZGXLyQw",
    "outputId": "37f515f7-c6cf-4e78-bebe-7c2771037b0b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1629726405581,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "8yAKNWhCDX4q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "from numpy.random import randint\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1629726405582,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "AL-c62j79iU-",
    "outputId": "296f1772-63ed-4df6-9fd4-7037232a7f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.device_count())\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1629726405583,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "L38TXio0GiWb",
    "outputId": "41ed87b1-b090-4a97-da39-102b8667bb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Add Cuda availability\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device, batchSize, *args, **kwargs):\n",
    "        super(DeviceDataLoader, self).__init__(dl, batchSize, *args, **kwargs)\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        # for b in self.dl: \n",
    "        #   yield to_device(b, self.device)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        # super(DeviceDataLoader, self).__iter__()\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1629726405583,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "hLnhnx2iDX6W"
   },
   "outputs": [],
   "source": [
    "k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1629726405584,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "48jS-jAgbl6B"
   },
   "outputs": [],
   "source": [
    "# !cp  '/content/drive/Shareddrives/FYP/Colab Notebooks/NEW_Approach/Python Files/WeightsCreator.py' '/content'\n",
    "# !cp  '/content/drive/Shareddrives/FYP/Colab Notebooks/NEW_Approach/Python Files/HDF5dataset.py' '/content'\n",
    "from HDF5dataset import HDF5Dataset\n",
    "from WeightsCreator import make_weights_for_balanced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1629726405587,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "kOtsr5aFfk-d"
   },
   "outputs": [],
   "source": [
    "inputFeatures = int((4**k) / 2)\n",
    "# inputFeatures = 2\n",
    "layer_array = [512, 512, 256, 256]\n",
    "outputSize = 10\n",
    "momentum = 0.4\n",
    "dropoutProb = 0.5\n",
    "batchSize = 400\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data info added\n",
      "5 data info added\n",
      "10 data info added\n",
      "15 data info added\n",
      "20 data info added\n",
      "25 data info added\n",
      "30 data info added\n",
      "35 data info added\n",
      "40 data info added\n",
      "45 data info added\n",
      "1000 data info added\n",
      "2000 data info added\n",
      "3000 data info added\n",
      "4000 data info added\n",
      "5000 data info added\n",
      "6000 data info added\n",
      "7000 data info added\n",
      "8000 data info added\n",
      "9000 data info added\n",
      "10000 data info added\n",
      "11000 data info added\n",
      "12000 data info added\n",
      "13000 data info added\n",
      "14000 data info added\n",
      "15000 data info added\n",
      "16000 data info added\n",
      "17000 data info added\n",
      "18000 data info added\n",
      "19000 data info added\n",
      "20000 data info added\n",
      "21000 data info added\n",
      "22000 data info added\n",
      "23000 data info added\n",
      "24000 data info added\n",
      "25000 data info added\n",
      "26000 data info added\n",
      "27000 data info added\n",
      "28000 data info added\n",
      "29000 data info added\n",
      "30000 data info added\n",
      "31000 data info added\n",
      "32000 data info added\n",
      "33000 data info added\n",
      "34000 data info added\n",
      "35000 data info added\n",
      "36000 data info added\n",
      "37000 data info added\n",
      "38000 data info added\n",
      "39000 data info added\n",
      "40000 data info added\n",
      "41000 data info added\n",
      "42000 data info added\n",
      "43000 data info added\n",
      "44000 data info added\n",
      "45000 data info added\n",
      "46000 data info added\n",
      "47000 data info added\n",
      "48000 data info added\n",
      "49000 data info added\n",
      "50000 data info added\n",
      "51000 data info added\n",
      "52000 data info added\n",
      "53000 data info added\n",
      "54000 data info added\n",
      "55000 data info added\n",
      "56000 data info added\n",
      "57000 data info added\n",
      "58000 data info added\n",
      "59000 data info added\n",
      "60000 data info added\n",
      "61000 data info added\n",
      "62000 data info added\n",
      "63000 data info added\n",
      "64000 data info added\n",
      "65000 data info added\n",
      "66000 data info added\n",
      "67000 data info added\n",
      "68000 data info added\n",
      "69000 data info added\n",
      "70000 data info added\n",
      "71000 data info added\n",
      "72000 data info added\n",
      "73000 data info added\n",
      "74000 data info added\n",
      "75000 data info added\n",
      "76000 data info added\n",
      "77000 data info added\n",
      "78000 data info added\n",
      "79000 data info added\n",
      "80000 data info added\n",
      "81000 data info added\n",
      "82000 data info added\n",
      "83000 data info added\n",
      "84000 data info added\n",
      "85000 data info added\n",
      "86000 data info added\n",
      "87000 data info added\n",
      "88000 data info added\n",
      "89000 data info added\n",
      "90000 data info added\n",
      "91000 data info added\n",
      "92000 data info added\n",
      "93000 data info added\n",
      "94000 data info added\n",
      "95000 data info added\n",
      "96000 data info added\n",
      "97000 data info added\n",
      "98000 data info added\n",
      "99000 data info added\n",
      "100000 data info added\n",
      "101000 data info added\n",
      "102000 data info added\n",
      "103000 data info added\n",
      "104000 data info added\n",
      "105000 data info added\n",
      "106000 data info added\n",
      "107000 data info added\n",
      "108000 data info added\n",
      "109000 data info added\n",
      "110000 data info added\n",
      "111000 data info added\n",
      "112000 data info added\n",
      "113000 data info added\n",
      "114000 data info added\n",
      "115000 data info added\n",
      "116000 data info added\n",
      "117000 data info added\n",
      "118000 data info added\n",
      "119000 data info added\n",
      "120000 data info added\n",
      "121000 data info added\n",
      "122000 data info added\n",
      "123000 data info added\n",
      "124000 data info added\n",
      "125000 data info added\n",
      "126000 data info added\n",
      "127000 data info added\n",
      "128000 data info added\n",
      "129000 data info added\n",
      "130000 data info added\n",
      "131000 data info added\n",
      "132000 data info added\n",
      "133000 data info added\n",
      "134000 data info added\n",
      "135000 data info added\n",
      "136000 data info added\n",
      "137000 data info added\n",
      "138000 data info added\n",
      "139000 data info added\n",
      "140000 data info added\n",
      "141000 data info added\n",
      "142000 data info added\n",
      "143000 data info added\n",
      "144000 data info added\n",
      "145000 data info added\n",
      "146000 data info added\n",
      "147000 data info added\n",
      "148000 data info added\n",
      "149000 data info added\n",
      "150000 data info added\n",
      "151000 data info added\n",
      "152000 data info added\n",
      "153000 data info added\n",
      "154000 data info added\n",
      "155000 data info added\n",
      "156000 data info added\n",
      "157000 data info added\n",
      "158000 data info added\n",
      "159000 data info added\n",
      "160000 data info added\n",
      "161000 data info added\n",
      "162000 data info added\n",
      "163000 data info added\n",
      "164000 data info added\n",
      "165000 data info added\n",
      "166000 data info added\n",
      "167000 data info added\n",
      "168000 data info added\n",
      "169000 data info added\n",
      "170000 data info added\n",
      "171000 data info added\n",
      "172000 data info added\n",
      "173000 data info added\n",
      "174000 data info added\n",
      "175000 data info added\n",
      "176000 data info added\n",
      "177000 data info added\n",
      "178000 data info added\n",
      "179000 data info added\n",
      "180000 data info added\n",
      "181000 data info added\n",
      "182000 data info added\n",
      "183000 data info added\n",
      "184000 data info added\n",
      "185000 data info added\n",
      "186000 data info added\n",
      "187000 data info added\n",
      "188000 data info added\n",
      "189000 data info added\n",
      "190000 data info added\n",
      "191000 data info added\n",
      "192000 data info added\n",
      "193000 data info added\n",
      "194000 data info added\n",
      "195000 data info added\n",
      "196000 data info added\n",
      "197000 data info added\n",
      "198000 data info added\n",
      "199000 data info added\n",
      "200000 data info added\n",
      "201000 data info added\n",
      "202000 data info added\n",
      "203000 data info added\n",
      "204000 data info added\n",
      "205000 data info added\n",
      "206000 data info added\n",
      "207000 data info added\n",
      "208000 data info added\n",
      "209000 data info added\n",
      "210000 data info added\n",
      "211000 data info added\n",
      "212000 data info added\n",
      "213000 data info added\n",
      "214000 data info added\n",
      "215000 data info added\n",
      "216000 data info added\n",
      "217000 data info added\n",
      "218000 data info added\n",
      "219000 data info added\n",
      "220000 data info added\n",
      "221000 data info added\n",
      "222000 data info added\n",
      "223000 data info added\n",
      "224000 data info added\n",
      "225000 data info added\n",
      "226000 data info added\n",
      "227000 data info added\n",
      "228000 data info added\n",
      "229000 data info added\n",
      "230000 data info added\n",
      "231000 data info added\n",
      "232000 data info added\n",
      "233000 data info added\n",
      "234000 data info added\n",
      "235000 data info added\n",
      "236000 data info added\n",
      "237000 data info added\n",
      "238000 data info added\n",
      "239000 data info added\n",
      "240000 data info added\n",
      "241000 data info added\n",
      "242000 data info added\n",
      "243000 data info added\n",
      "244000 data info added\n",
      "245000 data info added\n",
      "246000 data info added\n",
      "247000 data info added\n",
      "248000 data info added\n",
      "249000 data info added\n",
      "250000 data info added\n",
      "251000 data info added\n",
      "252000 data info added\n",
      "253000 data info added\n",
      "254000 data info added\n",
      "255000 data info added\n",
      "256000 data info added\n",
      "257000 data info added\n",
      "258000 data info added\n",
      "259000 data info added\n",
      "260000 data info added\n",
      "261000 data info added\n",
      "262000 data info added\n",
      "263000 data info added\n",
      "264000 data info added\n",
      "265000 data info added\n",
      "266000 data info added\n",
      "267000 data info added\n",
      "268000 data info added\n",
      "269000 data info added\n",
      "270000 data info added\n",
      "271000 data info added\n",
      "272000 data info added\n",
      "273000 data info added\n",
      "274000 data info added\n",
      "275000 data info added\n",
      "276000 data info added\n",
      "277000 data info added\n",
      "278000 data info added\n",
      "279000 data info added\n",
      "280000 data info added\n",
      "281000 data info added\n",
      "282000 data info added\n",
      "283000 data info added\n",
      "284000 data info added\n",
      "285000 data info added\n",
      "286000 data info added\n",
      "287000 data info added\n",
      "288000 data info added\n",
      "289000 data info added\n",
      "290000 data info added\n",
      "291000 data info added\n",
      "292000 data info added\n"
     ]
    }
   ],
   "source": [
    "# trainingDataset = HDF5Dataset('Plasmid_0.008_Dataset.h5', True)\n",
    "#trainingDataset = HDF5Dataset('/home/chamikanandasiri/Test/Plasmid_0.008_Dataset.h5', True)\n",
    "trainingDataset = HDF5Dataset('/home/chamikanandasiri/Datasets/DNAML_Plasmid/DNAML_plasmid_train.h5', True)\n",
    "\n",
    "datasetsize = len(trainingDataset)\n",
    "train_size = int(0.8 * len(trainingDataset))\n",
    "val_size = len(trainingDataset) - train_size\n",
    "                     \n",
    "train_ds, val_ds = random_split(trainingDataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4498,
     "status": "ok",
     "timestamp": 1629726410041,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "frz2o0gQbwDg",
    "outputId": "c0619908-8eb7-4beb-becb-0048b520f0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.012647\n",
      "class counted in 0:00:00.000981\n",
      "0 entries labels processed\n",
      "5 entries labels processed\n",
      "10 entries labels processed\n",
      "15 entries labels processed\n",
      "20 entries labels processed\n",
      "25 entries labels processed\n",
      "30 entries labels processed\n",
      "35 entries labels processed\n",
      "40 entries labels processed\n",
      "45 entries labels processed\n",
      "1000 entries labels processed\n",
      "2000 entries labels processed\n",
      "3000 entries labels processed\n",
      "4000 entries labels processed\n",
      "5000 entries labels processed\n",
      "6000 entries labels processed\n",
      "7000 entries labels processed\n",
      "8000 entries labels processed\n",
      "9000 entries labels processed\n",
      "10000 entries labels processed\n",
      "11000 entries labels processed\n",
      "12000 entries labels processed\n",
      "13000 entries labels processed\n",
      "14000 entries labels processed\n",
      "15000 entries labels processed\n",
      "16000 entries labels processed\n",
      "17000 entries labels processed\n",
      "18000 entries labels processed\n",
      "19000 entries labels processed\n",
      "20000 entries labels processed\n",
      "21000 entries labels processed\n",
      "22000 entries labels processed\n",
      "23000 entries labels processed\n",
      "24000 entries labels processed\n",
      "25000 entries labels processed\n",
      "26000 entries labels processed\n",
      "27000 entries labels processed\n",
      "28000 entries labels processed\n",
      "29000 entries labels processed\n",
      "30000 entries labels processed\n",
      "31000 entries labels processed\n",
      "32000 entries labels processed\n",
      "33000 entries labels processed\n",
      "34000 entries labels processed\n",
      "35000 entries labels processed\n",
      "36000 entries labels processed\n",
      "37000 entries labels processed\n",
      "38000 entries labels processed\n",
      "39000 entries labels processed\n",
      "40000 entries labels processed\n",
      "41000 entries labels processed\n",
      "42000 entries labels processed\n",
      "43000 entries labels processed\n",
      "44000 entries labels processed\n",
      "45000 entries labels processed\n",
      "46000 entries labels processed\n",
      "47000 entries labels processed\n",
      "48000 entries labels processed\n",
      "49000 entries labels processed\n",
      "50000 entries labels processed\n",
      "51000 entries labels processed\n",
      "52000 entries labels processed\n",
      "53000 entries labels processed\n",
      "54000 entries labels processed\n",
      "55000 entries labels processed\n",
      "56000 entries labels processed\n",
      "57000 entries labels processed\n",
      "58000 entries labels processed\n",
      "59000 entries labels processed\n",
      "60000 entries labels processed\n",
      "61000 entries labels processed\n",
      "62000 entries labels processed\n",
      "63000 entries labels processed\n",
      "64000 entries labels processed\n",
      "65000 entries labels processed\n",
      "66000 entries labels processed\n",
      "67000 entries labels processed\n",
      "68000 entries labels processed\n",
      "69000 entries labels processed\n",
      "70000 entries labels processed\n",
      "71000 entries labels processed\n",
      "72000 entries labels processed\n",
      "73000 entries labels processed\n",
      "74000 entries labels processed\n",
      "75000 entries labels processed\n",
      "76000 entries labels processed\n",
      "77000 entries labels processed\n",
      "78000 entries labels processed\n",
      "79000 entries labels processed\n",
      "80000 entries labels processed\n",
      "81000 entries labels processed\n",
      "82000 entries labels processed\n",
      "83000 entries labels processed\n",
      "84000 entries labels processed\n",
      "85000 entries labels processed\n",
      "86000 entries labels processed\n",
      "87000 entries labels processed\n",
      "88000 entries labels processed\n",
      "89000 entries labels processed\n",
      "90000 entries labels processed\n",
      "91000 entries labels processed\n",
      "92000 entries labels processed\n",
      "93000 entries labels processed\n",
      "94000 entries labels processed\n",
      "95000 entries labels processed\n",
      "96000 entries labels processed\n",
      "97000 entries labels processed\n",
      "98000 entries labels processed\n",
      "99000 entries labels processed\n",
      "100000 entries labels processed\n",
      "101000 entries labels processed\n",
      "102000 entries labels processed\n",
      "103000 entries labels processed\n",
      "104000 entries labels processed\n",
      "105000 entries labels processed\n",
      "106000 entries labels processed\n",
      "107000 entries labels processed\n",
      "108000 entries labels processed\n",
      "109000 entries labels processed\n",
      "110000 entries labels processed\n",
      "111000 entries labels processed\n",
      "112000 entries labels processed\n",
      "113000 entries labels processed\n",
      "114000 entries labels processed\n",
      "115000 entries labels processed\n",
      "116000 entries labels processed\n",
      "117000 entries labels processed\n",
      "118000 entries labels processed\n",
      "119000 entries labels processed\n",
      "120000 entries labels processed\n",
      "121000 entries labels processed\n",
      "122000 entries labels processed\n",
      "123000 entries labels processed\n",
      "124000 entries labels processed\n",
      "125000 entries labels processed\n",
      "126000 entries labels processed\n",
      "127000 entries labels processed\n",
      "128000 entries labels processed\n",
      "129000 entries labels processed\n",
      "130000 entries labels processed\n",
      "131000 entries labels processed\n",
      "132000 entries labels processed\n",
      "133000 entries labels processed\n",
      "134000 entries labels processed\n",
      "135000 entries labels processed\n",
      "136000 entries labels processed\n",
      "137000 entries labels processed\n",
      "138000 entries labels processed\n",
      "139000 entries labels processed\n",
      "140000 entries labels processed\n",
      "141000 entries labels processed\n",
      "142000 entries labels processed\n",
      "143000 entries labels processed\n",
      "144000 entries labels processed\n",
      "145000 entries labels processed\n",
      "146000 entries labels processed\n",
      "147000 entries labels processed\n",
      "148000 entries labels processed\n",
      "149000 entries labels processed\n",
      "150000 entries labels processed\n",
      "151000 entries labels processed\n",
      "152000 entries labels processed\n",
      "153000 entries labels processed\n",
      "154000 entries labels processed\n",
      "155000 entries labels processed\n",
      "156000 entries labels processed\n",
      "157000 entries labels processed\n",
      "158000 entries labels processed\n",
      "159000 entries labels processed\n",
      "160000 entries labels processed\n",
      "161000 entries labels processed\n",
      "162000 entries labels processed\n",
      "163000 entries labels processed\n",
      "164000 entries labels processed\n",
      "165000 entries labels processed\n",
      "166000 entries labels processed\n",
      "167000 entries labels processed\n",
      "168000 entries labels processed\n",
      "169000 entries labels processed\n",
      "170000 entries labels processed\n",
      "171000 entries labels processed\n",
      "172000 entries labels processed\n",
      "173000 entries labels processed\n",
      "174000 entries labels processed\n",
      "175000 entries labels processed\n",
      "176000 entries labels processed\n",
      "177000 entries labels processed\n",
      "178000 entries labels processed\n",
      "179000 entries labels processed\n",
      "180000 entries labels processed\n",
      "181000 entries labels processed\n",
      "182000 entries labels processed\n",
      "183000 entries labels processed\n",
      "184000 entries labels processed\n",
      "185000 entries labels processed\n",
      "186000 entries labels processed\n",
      "187000 entries labels processed\n",
      "188000 entries labels processed\n",
      "189000 entries labels processed\n",
      "190000 entries labels processed\n",
      "191000 entries labels processed\n",
      "192000 entries labels processed\n",
      "193000 entries labels processed\n",
      "194000 entries labels processed\n",
      "195000 entries labels processed\n",
      "196000 entries labels processed\n",
      "197000 entries labels processed\n",
      "198000 entries labels processed\n",
      "199000 entries labels processed\n",
      "200000 entries labels processed\n",
      "201000 entries labels processed\n",
      "202000 entries labels processed\n",
      "203000 entries labels processed\n",
      "204000 entries labels processed\n",
      "205000 entries labels processed\n",
      "206000 entries labels processed\n",
      "207000 entries labels processed\n",
      "208000 entries labels processed\n",
      "209000 entries labels processed\n",
      "210000 entries labels processed\n",
      "211000 entries labels processed\n",
      "212000 entries labels processed\n",
      "213000 entries labels processed\n",
      "214000 entries labels processed\n",
      "215000 entries labels processed\n",
      "216000 entries labels processed\n",
      "217000 entries labels processed\n",
      "218000 entries labels processed\n",
      "219000 entries labels processed\n",
      "220000 entries labels processed\n",
      "221000 entries labels processed\n",
      "222000 entries labels processed\n",
      "223000 entries labels processed\n",
      "224000 entries labels processed\n",
      "225000 entries labels processed\n",
      "226000 entries labels processed\n",
      "227000 entries labels processed\n",
      "228000 entries labels processed\n",
      "229000 entries labels processed\n",
      "230000 entries labels processed\n",
      "231000 entries labels processed\n",
      "232000 entries labels processed\n",
      "233000 entries labels processed\n",
      "5:33:25.653339\n"
     ]
    }
   ],
   "source": [
    "#tens = torch.tensor([int(label) for _, label in train_ds])\n",
    "\n",
    "t1 = datetime.now()\n",
    "rtye = torch.tensor(train_ds.indices)\n",
    "print(datetime.now()-t1)\n",
    "tens = train_ds.dataset.get_label_values(rtye)\n",
    "print(datetime.now()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight calculation started\n",
      "class counted in 0:00:00.012564\n",
      "class total in 0:00:00.023917\n",
      "weight per class declared in 0:00:00.045548\n",
      "weight per class calculated in 0:00:00.061468\n",
      "weights declared in 0:00:00.063182\n",
      "weights calculated in 0:00:03.141754\n"
     ]
    }
   ],
   "source": [
    "weights = make_weights_for_balanced_classes(outputSize, tens)\n",
    "# weights = weights\n",
    "# weights = torch.DoubleTensor(weights)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, datasetsize)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batchSize, shuffle=False, num_workers=num_workers, pin_memory=True, sampler=sampler)\n",
    "val_dl = DataLoader(val_ds, batchSize, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# train_dl = DeviceDataLoader(train_ds, device, batchSize, shuffle=False, num_workers=num_workers, pin_memory=True, sampler=sampler)\n",
    "# val_dl = DeviceDataLoader(val_ds, device, batchSize, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1629726410045,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "CcWB_JAnNQ8i"
   },
   "outputs": [],
   "source": [
    "# index = 0\n",
    "# for i in train_dl:\n",
    "#   print(\"\\n\")\n",
    "#   print(i[0])\n",
    "#   print(\"\\n\")\n",
    "#   print(i[1])\n",
    "#   break\n",
    "\n",
    "  \n",
    "# train_dl = DeviceDataLoader(train_ds, device, batchSize, shuffle=False, num_workers=num_workers, pin_memory=True, sampler=sampler)\n",
    "# val_dl = DeviceDataLoader(val_ds, device, batchSize, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# index = 0\n",
    "# for i in train_dl:\n",
    "#   print(\"\\n\")\n",
    "#   print(i[0])\n",
    "#   print(\"\\n\")\n",
    "#   print(i[1])\n",
    "#   break\n",
    "\n",
    "# print(type(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGZS3O_a1w2H"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1629726410047,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "RRn9NdbPDX9-"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "\n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_size, layer_array = [512, 512, 256, 256], out_size = 28):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "          nn.Linear(in_size, layer_array[0]),\n",
    "          nn.ReLU(),\n",
    "          # nn.Dropout(dropoutProb),\n",
    "          nn.Linear(layer_array[0], layer_array[1]),\n",
    "          nn.ReLU(),\n",
    "          # nn.Dropout(dropoutProb),\n",
    "          nn.Linear(layer_array[1], layer_array[2]),\n",
    "          nn.ReLU(),\n",
    "          # nn.Dropout(dropoutProb),\n",
    "          nn.Linear(layer_array[2], layer_array[3]),\n",
    "          nn.ReLU(),\n",
    "          # nn.Dropout(dropoutProb),\n",
    "          nn.Linear(layer_array[3], out_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        softmax = nn.LogSoftmax(dim=0)\n",
    "        return softmax(self.network(xb))\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        values, labels = batch \n",
    "        values = values.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = self(values)                  # Generate predictions\n",
    "        loss = nn.functional.nll_loss(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        values, labels = batch \n",
    "        values = values.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = self(values)                    # Generate predictions\n",
    "        loss = nn.functional.nll_loss(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "\n",
    "def predict_image(value, model):\n",
    "  xb = value\n",
    "  # //:TODO Check torch.stack\n",
    "  # xb = torch.stack(value)\n",
    "  yb = model(xb)\n",
    "  _, preds  = torch.max(yb, dim=0)\n",
    "  return preds\n",
    "\n",
    "def predict_image(value, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(value, device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability   \n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return dataset.classes[preds[0].item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1629726410048,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "Q86pntFwOJtl",
    "outputId": "fe37be9d-fe89-4a5a-9ae4-76b79abc55f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputFeatures, layer_array, outputSize)\n",
    "model = to_device(model, device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101786,
     "status": "ok",
     "timestamp": 1629726511813,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "yBmGGPzXOJvJ",
    "outputId": "9b6acad7-8c1d-4064-fc9c-bab2bed5947e"
   },
   "outputs": [],
   "source": [
    "model.double()\n",
    "t = datetime.now()\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n",
    "print(datetime.now()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MR63CvxN1qR"
   },
   "source": [
    "0:01:40.396880\\\n",
    "0:02:31.303028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1629726511850,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "3pJ4vbkGOJzU",
    "outputId": "d2fb76fe-7f77-4df0-a65a-a731367d585d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1629726511852,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "iFTRQmYYaZ6I",
    "outputId": "88ac17d7-d0e3-47cf-b416-fd3bec383654"
   },
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "error",
     "timestamp": 1629726521326,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "ejrECRkDacq8",
    "outputId": "cc2bb6f0-5561-479c-ab91-a70dafadf449"
   },
   "outputs": [],
   "source": [
    "predict_image(torch.from_numpy(train_ds([0][0]), model) , train_ds([0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "aborted",
     "timestamp": 1629726521321,
     "user": {
      "displayName": "Chamika Nandasiri",
      "photoUrl": "",
      "userId": "09358068144481598376"
     },
     "user_tz": -330
    },
    "id": "KcwDLaPOodlc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Plasmid_Chromosome Model 0.2.0 gayal.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "512e37b7d70830a076d571c03e151ea37a1f12d335154b2c7bc3f18c509a262e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "072ef73d802248c1a1b428ef76ab20f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d620081f1f4709a7e85541b8dfe380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a1e2dfeb9214e8b8ed29b6dc9b4d5d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "479b5fb3c02a4254b4096e7b0b3f6206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b420378f71ff4dcd9200d016d5d672b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7b2d605492447c98736972271a1ae9e",
       "IPY_MODEL_be68e70880704bc7a219ba27f0a7e269"
      ],
      "layout": "IPY_MODEL_d6a2e0c8c18d4f07aed946a70a7c116e"
     }
    },
    "be68e70880704bc7a219ba27f0a7e269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_072ef73d802248c1a1b428ef76ab20f9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09d620081f1f4709a7e85541b8dfe380",
      "value": 1
     }
    },
    "c7b2d605492447c98736972271a1ae9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a1e2dfeb9214e8b8ed29b6dc9b4d5d3",
      "placeholder": "​",
      "style": "IPY_MODEL_479b5fb3c02a4254b4096e7b0b3f6206",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "d6a2e0c8c18d4f07aed946a70a7c116e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
